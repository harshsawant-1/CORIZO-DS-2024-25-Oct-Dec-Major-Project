Project Description: Semiconductor Manufacturing Process Analysis
Overview
In this capstone project, we aim to develop a predictive classification model for yield analysis in a semiconductor manufacturing process. The modern semiconductor manufacturing industry relies heavily on real-time monitoring via sensor signals. However, not all collected signals contribute meaningfully to understanding and improving production yield. This project emphasizes feature selection to identify the most relevant signals, enabling engineers to focus on key factors that influence production outcomes.

Our ultimate goal is to enhance production throughput, reduce time-to-insights, and lower per-unit production costs by accurately predicting pass/fail outcomes for manufacturing entities. The project also evaluates whether all the features in the dataset are necessary to build an efficient model.

Dataset Description
File Name: sensor-data.csv
Dimensions: 1567 examples (rows) and 591 features (columns) + target column.
Target Variable:
-1: Pass
1: Fail
Features: Sensor signals and measurement points recorded during production. These signals potentially include noise and irrelevant information.
Project Objectives
Build a classifier to predict the pass/fail yield of a semiconductor production entity.
Analyze feature relevance to determine if all available signals are necessary for building the model.
Enhance process throughput by leveraging insights into critical features.
Steps and Tasks
1. Import and Explore Data
Load the data and review the structure, size, and general characteristics.
Identify the distribution of the target variable.
2. Data Cleansing
Handle missing values and drop redundant or irrelevant features based on functional knowledge.
Make logical or functional modifications to prepare data for analysis.
3. Data Analysis & Visualization
Conduct detailed statistical analysis to identify trends and relationships in the data.
Perform univariate analysis (individual feature distribution), bivariate analysis (relationship with the target), and multivariate analysis (interactions among multiple features).
4. Data Preprocessing
Segregate predictors (features) and target attributes.
Address class imbalance using techniques like SMOTE.
Perform train-test splitting and data standardization to prepare the dataset for machine learning.
Verify that train and test sets maintain statistical similarity with the original dataset.
5. Model Training, Testing, and Tuning
Select and evaluate at least three supervised learning models:
Random Forest
Support Vector Machine (SVM)
Naive Bayes
Optimize models using GridSearchCV for hyperparameter tuning.
Leverage techniques such as:
Dimensionality reduction
Feature engineering
Standardization or normalization
Evaluate performance using precision, recall, F1-score, and accuracy metrics.
Compare models and select the best-performing one for deployment.
6. Conclusion and Future Improvements
Summarize findings and provide actionable recommendations.
Suggest improvements, including real-world deployment strategies and further research.
Deliverables
Code Notebook: Fully annotated notebook implementing all steps with visualizations and explanations.
Final Model: Trained and saved machine learning model ready for deployment.
README File: Brief documentation of the project for easy understanding.
